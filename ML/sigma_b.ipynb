{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c900f-779f-4521-83cb-d82c0c2246f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❄️ Sezon 2015/2016\n",
      " ▶ 2015-11-01\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-02\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-03\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-04\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-05\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-06\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-07\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-08\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-09\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-10\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-11\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-12\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-13\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-14\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-15\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-16\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-17\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-18\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-19\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-20\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-21\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-22\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-23\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-24\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-25\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-26\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-27\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-28\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-29\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-11-30\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-01\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-02\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-03\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-04\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-05\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-06\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-07\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-08\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-09\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-10\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-11\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-12\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-13\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-14\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-15\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-16\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-17\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-18\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-19\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-20\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-21\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-22\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-23\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-24\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-25\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-26\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-27\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-28\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-29\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-30\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2015-12-31\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-01\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-02\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-03\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-04\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-05\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-06\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-07\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-08\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-09\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-10\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-11\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-12\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-13\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-14\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-15\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-16\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-17\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-18\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-19\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-20\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-21\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-22\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-23\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-24\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-25\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-26\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-27\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-28\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-29\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-30\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-01-31\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-01\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-02\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-03\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-04\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-05\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-06\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-07\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-08\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-09\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-10\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-11\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-12\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-13\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-14\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-15\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-16\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-17\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-18\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-19\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-20\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-21\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-22\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-23\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-24\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-25\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-26\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-27\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-02-28\n",
      "   ⚠️ Brak danych\n",
      "\n",
      "❄️ Sezon 2016/2017\n",
      " ▶ 2016-11-01\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-02\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-03\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-04\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-05\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-06\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-07\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-08\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-09\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-10\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-11\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-12\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-13\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-14\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-15\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-16\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-17\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-18\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-19\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-20\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-21\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-22\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-23\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-24\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-25\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-26\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-27\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-28\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-29\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-11-30\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-01\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-02\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-03\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-04\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-05\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-06\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-07\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-08\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-09\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-10\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-11\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-12\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-13\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-14\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-15\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-16\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-17\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-18\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-19\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-20\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-21\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-22\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-23\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-24\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-25\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-26\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-27\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-28\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-29\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-30\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2016-12-31\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-01\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-02\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-03\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-04\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-05\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-06\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-07\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-08\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-09\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-10\n",
      "   ⚠️ Brak danych\n",
      " ▶ 2017-01-11\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot write NetCDF files because none of the suitable backend libraries (netCDF4, h5netcdf, scipy) are installed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m     92\u001b[39m ds = xr.Dataset(\n\u001b[32m     93\u001b[39m     {\n\u001b[32m     94\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mndsi\u001b[39m\u001b[33m\"\u001b[39m: da,\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m     },\n\u001b[32m    102\u001b[39m )\n\u001b[32m    104\u001b[39m output_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ndsi_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.nc\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ✅ zapisano \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/xarray/core/dataset.py:2110\u001b[39m, in \u001b[36mDataset.to_netcdf\u001b[39m\u001b[34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001b[39m\n\u001b[32m   2107\u001b[39m     encoding = {}\n\u001b[32m   2108\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxarray\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwriters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[32m-> \u001b[39m\u001b[32m2110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[32m   2111\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2114\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2118\u001b[39m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2121\u001b[39m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2123\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/xarray/backends/writers.py:402\u001b[39m, in \u001b[36mto_netcdf\u001b[39m\u001b[34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001b[39m\n\u001b[32m    399\u001b[39m normalized_path = _normalize_path(path_or_file)\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     engine = \u001b[43mget_default_netcdf_write_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# validate Dataset keys, DataArray names, and attr keys/values\u001b[39;00m\n\u001b[32m    405\u001b[39m _validate_dataset_names(dataset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/xarray/backends/writers.py:214\u001b[39m, in \u001b[36mget_default_netcdf_write_engine\u001b[39m\u001b[34m(path_or_file, format)\u001b[39m\n\u001b[32m    212\u001b[39m     format_str = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    213\u001b[39m libraries = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(module_names[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m candidates)\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    215\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcannot write NetCDF files\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformat_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m because none of the suitable \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbackend libraries (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibraries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) are installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    217\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: cannot write NetCDF files because none of the suitable backend libraries (netCDF4, h5netcdf, scipy) are installed"
     ]
    }
   ],
   "source": [
    "import planetary_computer as pc\n",
    "from pystac_client import Client\n",
    "import stackstac\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import xarray as xr \n",
    "\n",
    "# ---------------- PARAMETRY ----------------\n",
    "# BBOX = [19.03, 49.69, 19.15, 49.78]\n",
    "BBOX = [16.781111, 50.228889, 16.843611, 50.270556]\n",
    "EPSG = 32634\n",
    "RESOLUTION = 20\n",
    "MAX_CLOUD = 10\n",
    "NDSI_THRESHOLD = 0.4\n",
    "\n",
    "START_YEAR = 2015\n",
    "END_YEAR = datetime.now().year\n",
    "\n",
    "OUTPUT_DIR = \"./ndsi_daily_czarna\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# -------------------------------------------\n",
    "\n",
    "catalog = Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=pc.sign_inplace,\n",
    ")\n",
    "\n",
    "def daterange(start, end):\n",
    "    for n in range(int((end - start).days) + 1):\n",
    "        yield start + timedelta(n)\n",
    "\n",
    "# --- PĘTLA PO SEZONACH ---\n",
    "for season_year in range(START_YEAR, END_YEAR):\n",
    "    print(f\"\\n❄️ Sezon {season_year}/{season_year+1}\")\n",
    "\n",
    "    start_date = datetime(season_year, 11, 1)\n",
    "    end_date = datetime(season_year + 1, 2, 28)\n",
    "\n",
    "    for day in daterange(start_date, end_date):\n",
    "\n",
    "        date_str = day.strftime(\"%Y-%m-%d\")\n",
    "        print(f\" ▶ {date_str}\")\n",
    "\n",
    "        search = catalog.search(\n",
    "            collections=[\"sentinel-2-l2a\"],\n",
    "            bbox=BBOX,\n",
    "            datetime=f\"{date_str}/{date_str}\",\n",
    "            query={\"eo:cloud_cover\": {\"lt\": MAX_CLOUD}},\n",
    "        )\n",
    "\n",
    "        items = list(search.items())\n",
    "        if not items:\n",
    "            print(\"   ⚠️ Brak danych\")\n",
    "            continue\n",
    "\n",
    "        # --- STACK DLA JEDNEGO DNIA ---\n",
    "        stack = stackstac.stack(\n",
    "            items,\n",
    "            assets=[\"B03\", \"B11\"],\n",
    "            resolution=RESOLUTION,\n",
    "            bounds_latlon=BBOX,\n",
    "            epsg=EPSG,\n",
    "            fill_value=np.nan,\n",
    "        )\n",
    "\n",
    "        green = stack.sel(band=\"B03\")\n",
    "        swir = stack.sel(band=\"B11\")\n",
    "\n",
    "        ndsi = (green - swir) / (green + swir)\n",
    "        ndsi = ndsi.where(~np.isinf(ndsi))\n",
    "\n",
    "        # --- JEŚLI WIELE SCEN TEGO DNIA → MEDIANA ---\n",
    "        ndsi_daily = ndsi.median(dim=\"time\", skipna=True).values\n",
    "\n",
    "        output_path = f\"{OUTPUT_DIR}/ndsi_{date_str}.tif\"\n",
    "\n",
    "        # --- ZAPIS DO XARRAY / NETCDF ---\n",
    "        da = xr.DataArray(\n",
    "            ndsi_daily.astype(np.float32),\n",
    "            dims=(\"y\", \"x\"),\n",
    "            name=\"ndsi\",\n",
    "            attrs={\n",
    "                \"description\": \"Daily median NDSI\",\n",
    "                \"ndsi_threshold\": NDSI_THRESHOLD,\n",
    "                \"source\": \"Sentinel-2 L2A\",\n",
    "                \"date\": date_str,\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        ds = xr.Dataset(\n",
    "            {\n",
    "                \"ndsi\": da,\n",
    "                \"snow_mask\": (da > NDSI_THRESHOLD).astype(\"uint8\"),\n",
    "            },\n",
    "            attrs={\n",
    "                \"bbox\": BBOX,\n",
    "                \"epsg\": EPSG,\n",
    "                \"resolution\": RESOLUTION,\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        output_path = f\"{OUTPUT_DIR}/ndsi_{date_str}.nc\"\n",
    "        ds.to_netcdf(output_path)\n",
    "        \n",
    "        print(f\"   ✅ zapisano {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197e3a8-b147-497f-8be6-f403ed1371de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aeff7e6",
   "metadata": {},
   "source": [
    "# NDSI Forecasting (Train + Predict)\n",
    "This section trains a simple regression model on historical daily NDSI GeoTIFFs (ndsi_YYYY-MM-DD.tif) and writes a predicted GeoTIFF for a future date.\n",
    "\n",
    "Notes:\n",
    "- Works best when all rasters in the folder have the same grid/shape/CRS.\n",
    "- The model is a baseline (RandomForest) trained on sampled pixels with lagged NDSI + day-of-year features.\n",
    "- For “incoming winter season” style forecasting, train with lead=1 and use the rollout command to recursively write predictions over a whole date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import joblib\n",
    "\n",
    "# Ensure we can import ndsi_forecast.py regardless of notebook working directory\n",
    "if Path(\"ndsi_forecast.py\").exists():\n",
    "    sys.path.insert(0, str(Path(\".\").resolve()))\n",
    "elif Path(\"BITEHACK/ML/ndsi_forecast.py\").exists():\n",
    "    sys.path.insert(0, str(Path(\"BITEHACK/ML\").resolve()))\n",
    "else:\n",
    "    raise FileNotFoundError(\"Can't find ndsi_forecast.py\")\n",
    "\n",
    "from ndsi_forecast import train_model\n",
    "\n",
    "# Pick one dataset folder with GeoTIFFs named like ndsi_YYYY-MM-DD.tif\n",
    "DATA_DIR = Path(\"./ndsi_daily_szczyrk\")\n",
    "if not DATA_DIR.exists():\n",
    "    DATA_DIR = Path(\"BITEHACK/ML/ndsi_daily_szczyrk\")\n",
    "\n",
    "MODEL_PATH = Path(\"./models/ndsi_szczyrk_rf.joblib\")\n",
    "\n",
    "bundle = train_model(\n",
    "    DATA_DIR,\n",
    "    lookback=7,   # how many past days to use as input\n",
    "    lead=7,       # how many days ahead to predict\n",
    "    sample_pixels_per_day=2000,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(bundle, MODEL_PATH)\n",
    "\n",
    "bundle[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b52c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import sys\n",
    "import joblib\n",
    "\n",
    "# Ensure we can import ndsi_forecast.py regardless of notebook working directory\n",
    "if Path(\"ndsi_forecast.py\").exists():\n",
    "    sys.path.insert(0, str(Path(\".\").resolve()))\n",
    "elif Path(\"BITEHACK/ML/ndsi_forecast.py\").exists():\n",
    "    sys.path.insert(0, str(Path(\"BITEHACK/ML\").resolve()))\n",
    "else:\n",
    "    raise FileNotFoundError(\"Can't find ndsi_forecast.py\")\n",
    "\n",
    "from ndsi_forecast import predict_to_tif\n",
    "\n",
    "DATA_DIR = Path(\"./ndsi_daily_szczyrk\")\n",
    "if not DATA_DIR.exists():\n",
    "    DATA_DIR = Path(\"BITEHACK/ML/ndsi_daily_szczyrk\")\n",
    "\n",
    "MODEL_PATH = Path(\"./models/ndsi_szczyrk_rf.joblib\")\n",
    "bundle = joblib.load(MODEL_PATH)\n",
    "\n",
    "# If target_date=None -> predicts (last_available_date + lead)\n",
    "# Or set an explicit date, e.g.: target_date = date(2026, 11, 15)\n",
    "target_date = None\n",
    "\n",
    "out_dir = Path(\"./predictions\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = out_dir / \"pred_ndsi.tif\"\n",
    "written = predict_to_tif(bundle, DATA_DIR, target_date=target_date, output_path=out_path)\n",
    "written"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
